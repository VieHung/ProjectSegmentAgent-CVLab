import torch
import cv2
import numpy as np
import os
from core.interfaces import InpaintingStrategy

class DeepInpaintingStrategy(InpaintingStrategy):
    """
    Success Case 2: S·ª≠ d·ª•ng LaMa (Large Mask Inpainting) - Model SOTA.
    Y√™u c·∫ßu: File weights/big-lama.pt
    """
    def __init__(self, model_path="weights/big-lama.pt", device=None):
        # 1. C·∫•u h√¨nh thi·∫øt b·ªã (∆Øu ti√™n GPU n·∫øu c√≥)
        if device is None:
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
            
        print(f"üöÄ [DeepInpainting] Initializing LaMa model on {self.device}...")

        # 2. Load Model th·∫≠t (TorchScript)
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y model t·∫°i: {model_path}\nüëâ H√£y t·∫£i file big-lama.pt v√† b·ªè v√†o folder weights/ !")
        
        try:
            # Load model d·∫°ng JIT (ƒë√£ g√≥i g·ªçn ki·∫øn tr√∫c + weight)
            self.model = torch.jit.load(model_path, map_location=self.device)
            self.model.eval()
            print("‚úÖ Load model LaMa th√†nh c√¥ng!")
        except Exception as e:
            raise RuntimeError(f"‚ùå L·ªói khi load model big-lama.pt: {e}")

    def process(self, image: np.ndarray, mask: np.ndarray) -> np.ndarray:
        """
        Quy tr√¨nh x·ª≠ l√Ω ·∫£nh qua Deep Learning Model
        """
        # --- 1. PRE-PROCESSING (Chu·∫©n b·ªã d·ªØ li·ªáu) ---
        # LaMa y√™u c·∫ßu k√≠ch th∆∞·ªõc ·∫£nh ph·∫£i chia h·∫øt cho 8
        h, w = image.shape[:2]
        new_h = (h // 8) * 8
        new_w = (w // 8) * 8
        
        # Resize ·∫£nh v√† mask
        img_resized = cv2.resize(image, (new_w, new_h))
        mask_resized = cv2.resize(mask, (new_w, new_h))

        # Chu·∫©n h√≥a v·ªÅ Tensor [0, 1] v√† format (Batch, Channel, Height, Width)
        # ·∫¢nh: (H, W, 3) -> (3, H, W) -> Chia 255
        img_tensor = torch.from_numpy(img_resized).float() / 255.0
        img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0).to(self.device)
        
        # Mask: (H, W) -> (1, H, W) -> Chia 255 (LaMa hi·ªÉu: 1 l√† v√πng c·∫ßn x√≥a, 0 l√† n·ªÅn)
        if len(mask_resized.shape) == 2:
            mask_tensor = torch.from_numpy(mask_resized).float() / 255.0
            mask_tensor = mask_tensor.unsqueeze(0).unsqueeze(0).to(self.device) # (1, 1, H, W)
        else:
             # N·∫øu mask input ƒë√£ l√† 3 k√™nh, l·∫•y 1 k√™nh th√¥i
            mask_tensor = torch.from_numpy(mask_resized[:,:,0]).float() / 255.0
            mask_tensor = mask_tensor.unsqueeze(0).unsqueeze(0).to(self.device)

        # Binarize mask (ƒë·∫£m b·∫£o mask ch·ªâ c√≥ 0 ho·∫∑c 1)
        mask_tensor = (mask_tensor > 0.5).float()

        # --- 2. INFERENCE (Ch·∫°y model) ---
        with torch.no_grad():
            # Model LaMa (b·∫£n JIT) th∆∞·ªùng nh·∫≠n ƒë·∫ßu v√†o l√† ·∫£nh v√† mask
            # M·ªôt s·ªë phi√™n b·∫£n y√™u c·∫ßu concat, nh∆∞ng b·∫£n big-lama.pt ph·ªï bi·∫øn ch·∫°y nh∆∞ sau:
            try:
                # C√°ch 1: Truy·ªÅn r·ªùi (Image, Mask) - Ph·ªï bi·∫øn v·ªõi Sanster/IOPaint export
                output_tensor = self.model(img_tensor, mask_tensor)
            except:
                # C√°ch 2: N·∫øu model y√™u c·∫ßu concat (Input 4 k√™nh)
                input_tensor = torch.cat([img_tensor, mask_tensor], dim=1)
                output_tensor = self.model(input_tensor)

        # --- 3. POST-PROCESSING (X·ª≠ l√Ω k·∫øt qu·∫£) ---
        # L·∫•y k·∫øt qu·∫£ t·ª´ GPU v·ªÅ CPU -> Numpy
        output_np = output_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
        output_np = np.clip(output_np * 255, 0, 255).astype(np.uint8)
        
        # Resize l·∫°i v·ªÅ k√≠ch th∆∞·ªõc g·ªëc ban ƒë·∫ßu c·ªßa user
        output_final = cv2.resize(output_np, (w, h))
        
        # K·ª∏ THU·∫¨T BLENDING: Ch·ªâ d√°n v√πng ƒë∆∞·ª£c inpaint v√†o ·∫£nh g·ªëc
        # (Gi·ªØ nguy√™n n·ªÅn g·ªëc s·∫Øc n√©t, ch·ªâ thay ch·ªó mask)
        mask_bool = mask > 0 # V√πng n√†o l√† mask th√¨ l·∫•y ·∫£nh m·ªõi
        
        final_result = image.copy()
        # L∆∞u √Ω: output_final c√≥ th·ªÉ h∆°i l·ªách m√†u m·ªôt ch√∫t do model,
        # nh∆∞ng v·ªõi LaMa th√¨ th∆∞·ªùng r·∫•t kh·ªõp.
        final_result[mask_bool] = output_final[mask_bool]
        
        return final_result