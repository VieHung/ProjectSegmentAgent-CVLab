import os
import torch
import cv2
import numpy as np
import sys


# Láº¥y Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i cá»§a thÆ° má»¥c chá»©a file hiá»‡n táº¡i (modules/grounding)
current_dir = os.path.dirname(os.path.abspath(__file__))

# ThÃªm thÆ° má»¥c nÃ y vÃ o sys.path Ä‘á»ƒ Python tÃ¬m tháº¥y folder 'GroundingDINO' náº±m cÃ¹ng cáº¥p
if current_dir not in sys.path:
    sys.path.append(current_dir)

from PIL import Image
import GroundingDINO.groundingdino.datasets.transforms as T
from GroundingDINO.groundingdino.util.inference import load_model, predict


class GroundingDINOStrategy:
    """
    PhiÃªn báº£n dÃ¹ng Official Repo (IDEA-Research) vá»›i file .pth
    """
    def __init__(self, 
                 config_path="weights/GroundingDINO_SwinB_cfg.py", 
                 weights_path="weights/groundingdino_swinb_cogcoor.pth", 
                 device=None):
        
        # 1. Cáº¥u hÃ¬nh thiáº¿t bá»‹
        if device is None:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
            
        print(f"ðŸš€ [GroundingDINO-Official] Initializing on {self.device}...")

        # 2. Kiá»ƒm tra file tá»“n táº¡i
        if not os.path.exists(config_path):
             raise FileNotFoundError(f"âŒ Thiáº¿u file config: {config_path}")
        if not os.path.exists(weights_path):
             raise FileNotFoundError(f"âŒ Thiáº¿u file weights: {weights_path}")

        # 3. Load Model báº±ng hÃ m cá»§a thÆ° viá»‡n gá»‘c
        try:
            self.model = load_model(config_path, weights_path, device=self.device)
            print("âœ… Load model .pth thÃ nh cÃ´ng!")
        except Exception as e:
            raise RuntimeError(f"âŒ Lá»—i load model: {e}")

    def transform_image(self, image_pil):
        """
        HÃ m xá»­ lÃ½ áº£nh theo chuáº©n cá»§a GroundingDINO
        """
        transform = T.Compose([
            T.RandomResize([800], max_size=1333),
            T.ToTensor(),
            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ])
        image_tensor, _ = transform(image_pil, None)
        return image_tensor

    def detect(self, image: np.ndarray, text_prompt: str, box_threshold=0.35, text_threshold=0.25):
        """
        Input: áº¢nh OpenCV (numpy) + Prompt
        Output: List boxes [x1, y1, x2, y2] (Pixel coordinates)
        """
        # --- 1. PRE-PROCESSING ---
        # Chuyá»ƒn OpenCV (BGR) -> PIL (RGB)
        image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        
        # Transform áº£nh sang Tensor (Chuáº©n hÃ³a)
        image_tensor = self.transform_image(image_pil)

        # --- 2. INFERENCE ---
        # HÃ m predict cá»§a thÆ° viá»‡n gá»‘c
        boxes, logits, phrases = predict(
            model=self.model,
            image=image_tensor,
            caption=text_prompt,
            box_threshold=box_threshold,
            text_threshold=text_threshold,
            device=self.device
        )

        # --- 3. POST-PROCESSING (Quan trá»ng) ---
        # Output 'boxes' cá»§a thÆ° viá»‡n gá»‘c á»Ÿ dáº¡ng: [cx, cy, w, h] (Center X, Center Y, Width, Height)
        # VÃ  giÃ¡ trá»‹ Ä‘Æ°á»£c CHUáº¨N HÃ“A vá» [0, 1].
        # ChÃºng ta cáº§n chuyá»ƒn vá»: [x1, y1, x2, y2] (Pixel thá»±c táº¿)
        
        h_img, w_img = image.shape[:2]
        boxes_pixel = []

        # Chuyá»ƒn tá»« Tensor vá» Numpy Ä‘á»ƒ tÃ­nh toÃ¡n
        boxes_np = boxes.cpu().numpy()

        for box in boxes_np:
            cx, cy, w, h = box
            
            # De-normalize (NhÃ¢n vá»›i kÃ­ch thÆ°á»›c áº£nh)
            cx *= w_img
            cy *= h_img
            w *= w_img
            h *= h_img

            # Chuyá»ƒn tá»« (Center, Size) -> (TopLeft, BottomRight)
            x1 = int(cx - w / 2)
            y1 = int(cy - h / 2)
            x2 = int(cx + w / 2)
            y2 = int(cy + h / 2)

            boxes_pixel.append([x1, y1, x2, y2])

        print(f"ðŸ”Ž TÃ¬m tháº¥y {len(boxes_pixel)} Ä‘á»‘i tÆ°á»£ng '{text_prompt}'")
        return np.array(boxes_pixel), logits

    def create_mask_from_boxes(self, image_shape, boxes):
        # (Giá»¯ nguyÃªn nhÆ° code cÅ©)
        h, w = image_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        for box in boxes:
            x1, y1, x2, y2 = box
            cv2.rectangle(mask, (x1, y1), (x2, y2), 255, -1)
        return mask