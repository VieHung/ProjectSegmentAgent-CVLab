import torch
import numpy as np
import os
import cv2
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor

class Sam2MaskStrategy:
    """
    Nhiá»‡m vá»¥: Táº¡o Mask cá»±c chuáº©n tá»« Box hoáº·c Point (KhÃ´ng pháº£i Ä‘á»ƒ xÃ³a váº­t thá»ƒ).
    YÃªu cáº§u: 
        - File checkpoint (.pt): vÃ­ dá»¥ sam2_hiera_large.pt
        - File config (.yaml): TÆ°Æ¡ng á»©ng vá»›i model (náº±m trong repo SAM2)
    """
    def __init__(self, 
                 checkpoint_path="weights/sam2_hiera_base_plus.pt", 
                 config_path="modules/segmentation/sam2/sam2_hiera_b+.yaml", # Cáº§n Ä‘Ãºng config cá»§a file .pt
                 device=None):
        
        # 1. Cáº¥u hÃ¬nh thiáº¿t bá»‹
        if device is None:
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
            
        print(f"ğŸš€ [Sam2Mask] Initializing SAM 2 on {self.device}...")

        if not os.path.exists(checkpoint_path):
            raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y weights táº¡i: {checkpoint_path}")

        try:
            # 2. Build Model tá»« Config vÃ  Checkpoint
            # SAM 2 khÃ¡c LaMa, nÃ³ cáº§n load kiáº¿n trÃºc tá»« file config yaml trÆ°á»›c
            sam2_model = build_sam2(config_path, checkpoint_path, device=self.device)
            
            # 3. Khá»Ÿi táº¡o Predictor (Wrapper giÃºp xá»­ lÃ½ áº£nh dá»… hÆ¡n)
            self.predictor = SAM2ImagePredictor(sam2_model)
            print("âœ… Load model SAM 2 thÃ nh cÃ´ng!")
            
        except Exception as e:
            raise RuntimeError(f"âŒ Lá»—i khi load SAM 2: {e}\nğŸ‘‰ Kiá»ƒm tra láº¡i file .yaml config cÃ³ khá»›p vá»›i file .pt khÃ´ng.")

    def process(self, image: np.ndarray, boxes=None, points=None, labels=None) -> np.ndarray:
        """
        Input:
            - image: áº¢nh gá»‘c (Numpy array RGB)
            - boxes: Bounding box [x1, y1, x2, y2] (tÃ¹y chá»n)
            - points: Tá»a Ä‘á»™ Ä‘iá»ƒm [[x, y]] (tÃ¹y chá»n)
            - labels: NhÃ£n cho Ä‘iá»ƒm (1: foreground, 0: background)
        Output:
            - final_mask: Mask nhá»‹ phÃ¢n (0 vÃ  255) chuáº©n kÃ­ch thÆ°á»›c áº£nh gá»‘c.
        """
        # --- 1. SET IMAGE (Encode áº£nh - BÆ°á»›c nÃ y tá»‘n time nháº¥t cá»§a SAM) ---
        # SAM 2 yÃªu cáº§u áº£nh RGB, uint8
        if hasattr(self, 'current_image_shape') and self.current_image_shape == image.shape:
             # (Optional) Náº¿u áº£nh khÃ´ng Ä‘á»•i thÃ¬ khÃ´ng cáº§n set láº¡i Ä‘á»ƒ tá»‘i Æ°u, 
             # nhÆ°ng an toÃ n nháº¥t lÃ  cá»© set láº¡i náº¿u dÃ¹ng cho API rá»i ráº¡c.
             pass
        
        self.predictor.set_image(image)

        # --- 2. PREDICT MASK ---
        # SAM 2 cÃ³ thá»ƒ nháº­n box hoáº·c point
        masks, scores, _ = self.predictor.predict(
            point_coords=points,
            point_labels=labels,
            box=boxes,
            multimask_output=False # Chá»‰ láº¥y 1 mask tá»‘t nháº¥t
        )

        # --- 3. POST-PROCESSING ---
        # masks tráº£ vá» shape (1, H, W) -> láº¥y ra (H, W)
        best_mask = masks[0]
        
        # Chuyá»ƒn vá» Ä‘á»‹nh dáº¡ng áº£nh grayscale (0-255) Ä‘á»ƒ dÃ¹ng cho LaMa
        final_mask_uint8 = (best_mask * 255).astype(np.uint8)

        return final_mask_uint8
